"""
SFT í•™ìŠµ ë°ì´í„° ìƒì„± ìŠ¤í¬ë¦½íŠ¸
ìˆ˜í•™ ìˆ˜ëŠ¥ ë¬¸ì œì— ëŒ€í•œ í’€ì´ë¥¼ vLLMìœ¼ë¡œ ìƒì„±í•˜ì—¬ SFT í•™ìŠµ ë°ì´í„°ë¥¼ ë§Œë“­ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python generate_sft_data.py [ì˜µì…˜]
    
    ë˜ëŠ” run_sft_pipeline.shë¥¼ í†µí•´ ì‹¤í–‰ (ê¶Œì¥)
"""
import os
import re
import json
import time
import glob
import aiohttp
import asyncio
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor
from openai import OpenAI

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘                    ğŸ”§ ê¸°ë³¸ ì„¤ì • (í•„ìš”ì‹œ ìˆ˜ì •)                            â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# ----------------------------------------------------------------------------
# ğŸ“ ê²½ë¡œ ì„¤ì •
# ----------------------------------------------------------------------------

# ì…ë ¥ ë°ì´í„° ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’)
# - *_math.jsonl, *_korean.jsonl íŒŒì¼ê³¼ sentences_ask_boxed*.jsonlì´ ìˆëŠ” í´ë”
DEFAULT_DATA_DIR = "./data"

# ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’)  
# - ìƒì„±ëœ SFT ë°ì´í„°ê°€ ì €ì¥ë˜ëŠ” í´ë”
DEFAULT_OUTPUT_DIR = "./sft_output"

# ----------------------------------------------------------------------------
# ğŸ¤– vLLM ì„œë²„ ì„¤ì •
# ----------------------------------------------------------------------------

# vLLM API ì„œë²„ URL (ê¸°ë³¸ê°’)
DEFAULT_BASE_URL = "http://10.0.74.208:8000/v1"

# ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„ (ê¸°ë³¸ê°’)
DEFAULT_MODEL = "glm-4.7"

# ----------------------------------------------------------------------------
# âš™ï¸ ìƒì„± ì„¤ì •
# ----------------------------------------------------------------------------

# ë¬¸ì œë‹¹ ìƒì„± íšŸìˆ˜ (ê¸°ë³¸ê°’)
# - ê° ë¬¸ì œì— ëŒ€í•´ ëª‡ ë²ˆ í’€ì´ë¥¼ ìƒì„±í• ì§€
DEFAULT_N = 10

# ë™ì‹œ ì›Œì»¤ ìˆ˜ (ê¸°ë³¸ê°’)
# - vLLM ì„œë²„ì— ë™ì‹œì— ë³´ë‚´ëŠ” ìš”ì²­ ìˆ˜
DEFAULT_WORKER = 20

# ì¶œë ¥ í˜•ì‹ (ê¸°ë³¸ê°’)
# - simple:   {"problem": ..., "solution": ..., "answer": ...}
# - sharegpt: {"messages": [{"role": "user", ...}, {"role": "assistant", ...}]}  
# - alpaca:   {"instruction": ..., "input": ..., "output": ...}
DEFAULT_FORMAT = "simple"

# ----------------------------------------------------------------------------
# ğŸŒ ë„¤íŠ¸ì›Œí¬ ì„¤ì •
# ----------------------------------------------------------------------------

# no_proxy ì„¤ì • (vLLM ì„œë²„ ì£¼ì†Œ - í”„ë¡ì‹œ ìš°íšŒ)
os.environ["no_proxy"] = "localhost,127.0.0.1,10.0.74.208"

# ============================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ============================================================================

def open_jsonl(path):
    """JSONL íŒŒì¼ì„ ì½ì–´ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜"""
    data = []
    with open(path, mode='r', encoding='utf8') as rf:
        for line in rf:
            line = line.strip()
            if line:
                data.append(json.loads(line))
    return data


def to_jsonl(out_path, data):
    """ë°ì´í„°ë¥¼ JSONL í˜•ì‹ìœ¼ë¡œ ì €ì¥"""
    with open(out_path, mode='w', encoding='utf8') as wf:
        for row in data:
            wf.write(json.dumps(row, ensure_ascii=False))
            wf.write('\n')


def append_jsonl(out_path, row):
    """ë‹¨ì¼ í•­ëª©ì„ JSONL íŒŒì¼ì— ì¶”ê°€"""
    with open(out_path, mode='a', encoding='utf8') as wf:
        wf.write(json.dumps(row, ensure_ascii=False))
        wf.write('\n')


# ============================================================================
# ë¬¸ì œ ì „ì²˜ë¦¬ í•¨ìˆ˜
# ============================================================================

def is_multiple_choice(problem_text: str) -> bool:
    """ê°ê´€ì‹ ë¬¸ì œì¸ì§€ íŒë³„í•©ë‹ˆë‹¤."""
    # ì„ íƒì§€ íŒ¨í„´ í™•ì¸: \item[1], \item[2], ... ë“±ì´ 5ê°œ ì´ìƒ ìˆëŠ”ì§€
    choice_pattern = r"\\item\[[1-5]\]"
    matches = re.findall(choice_pattern, problem_text)
    return len(matches) >= 5


def extract_choice_value(problem_text: str, choice_num: int) -> str:
    """
    ê°ê´€ì‹ ë¬¸ì œì—ì„œ íŠ¹ì • ë²ˆí˜¸ ì„ íƒì§€ì˜ ê°’ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    ì˜ˆ: \\item[2] \\frac{1}{2} â†’ choice_num=2 â†’ "\\frac{1}{2}"
    
    Args:
        problem_text: ë¬¸ì œ í…ìŠ¤íŠ¸
        choice_num: ì„ íƒì§€ ë²ˆí˜¸ (1-5)
    
    Returns:
        ì„ íƒì§€ ê°’ (ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ ì›ë³¸ choice_numì„ ë¬¸ìì—´ë¡œ ë°˜í™˜)
    """
    # \item[N] ë‹¤ìŒì˜ ê°’ì„ ì¶”ì¶œ (ë‹¤ìŒ \itemì´ë‚˜ \end{itemize} ì „ê¹Œì§€)
    pattern = rf"\\item\[{choice_num}\]\s*(.+?)(?=\\item\[|\\end\{{itemize\}}|$)"
    match = re.search(pattern, problem_text, re.DOTALL)
    if match:
        value = match.group(1).strip()
        # ì¤„ë°”ê¿ˆ ì œê±°
        value = re.sub(r'\s+', ' ', value)
        return value
    return str(choice_num)


def remove_choices(problem_text: str) -> str:
    """
    ê°ê´€ì‹ ë¬¸ì œì—ì„œ ì„ íƒì§€ë¥¼ ì œê±°í•˜ì—¬ ì£¼ê´€ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    ì œê±° íŒ¨í„´:
    - \\begin{itemize} ... \\end{itemize} ë¸”ë¡ ì „ì²´
    """
    text = problem_text
    
    # LaTeX itemize í™˜ê²½ ì œê±° (ì—¬ëŸ¬ íŒ¨í„´ ì‹œë„)
    # íŒ¨í„´ 1: \begin{itemize} ... \end{itemize}
    text = re.sub(r'\\begin\{itemize\}.*?\\end\{itemize\}', '', text, flags=re.DOTALL)
    
    # íŒ¨í„´ 2: \\begin{itemize} ... \\end{itemize} (ì´ìŠ¤ì¼€ì´í”„ëœ ë²„ì „)
    text = re.sub(r'\\\\begin\{itemize\}.*?\\\\end\{itemize\}', '', text, flags=re.DOTALL)
    
    # ì„ íƒì§€ ë²ˆí˜¸ íŒ¨í„´ ì œê±° (1) (2) (3) (4) (5) ë˜ëŠ” â‘  â‘¡ â‘¢ â‘£ â‘¤
    text = re.sub(r'\s*\([1-5]\)\s*[^\(\n]*', '', text)
    text = re.sub(r'\s*[â‘ â‘¡â‘¢â‘£â‘¤]\s*[^\n]*', '', text)
    
    # ì—°ì† ê³µë°±/ì¤„ë°”ê¿ˆ ì •ë¦¬
    text = re.sub(r'\n\s*\n', '\n', text)
    text = re.sub(r'  +', ' ', text)
    
    return text.strip()


def clean_problem_text(problem_text: str, remove_mc_choices: bool = False) -> str:
    """
    ë¬¸ì œ í…ìŠ¤íŠ¸ì—ì„œ ë²ˆí˜¸ì™€ ì ìˆ˜ë¥¼ ì œê±°í•©ë‹ˆë‹¤.
    
    ì œê±° íŒ¨í„´:
    - ë¬¸ì œ ë²ˆí˜¸: "1. ", "12. " ë“± (ë¬¸ìì—´ ì‹œì‘ ë¶€ë¶„)
    - ì ìˆ˜ í‘œì‹œ: "[2ì ]", "[3ì ]", "[4ì ]" ë“±
    
    Args:
        remove_mc_choices: Trueë©´ ê°ê´€ì‹ ì„ íƒì§€ë„ ì œê±°
    
    LaTeX í˜•ì‹ì€ ìœ ì§€í•©ë‹ˆë‹¤.
    """
    text = problem_text.strip()
    
    # ë¬¸ì œ ë²ˆí˜¸ ì œê±° (ì‹œì‘ ë¶€ë¶„ì˜ "ìˆ«ì. " íŒ¨í„´)
    text = re.sub(r'^(\d+)\.\s*', '', text)
    
    # ì ìˆ˜ í‘œì‹œ ì œê±° ("[2ì ]", "[3ì ]" ë“±)
    text = re.sub(r'\s*\[\d+ì \]\s*', ' ', text)
    
    # ê°ê´€ì‹ ì„ íƒì§€ ì œê±° (ì˜µì…˜)
    if remove_mc_choices:
        text = remove_choices(text)
    
    # ì—°ì† ê³µë°± ì •ë¦¬
    text = re.sub(r'  +', ' ', text)
    
    return text.strip()


# ============================================================================
# í”„ë¡¬í”„íŠ¸ ìƒì„±
# ============================================================================

def get_prompt(problem_text: str, request_sentences: list, generation_id: int = 0,
               as_subjective: bool = False) -> str:
    """
    ë¬¸ì œì™€ boxed ìš”ì²­ ë¬¸ì¥ì„ ì¡°í•©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        problem_text: ì›ë³¸ ë¬¸ì œ í…ìŠ¤íŠ¸
        request_sentences: boxed ìš”ì²­ ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸
        generation_id: ìƒì„± ì¸ë±ìŠ¤ (í”„ë¡¬í”„íŠ¸ ë³€í˜•ì— ì‚¬ìš©)
        as_subjective: Trueë©´ ê°ê´€ì‹ ì„ íƒì§€ë¥¼ ì œê±°í•˜ì—¬ ì£¼ê´€ì‹ìœ¼ë¡œ ë³€í™˜
    """
    # ë¬¸ì œ ì „ì²˜ë¦¬ (ë²ˆí˜¸/ì ìˆ˜ ì œê±°, ì„ íƒì§€ ì œê±° ì˜µì…˜)
    cleaned_problem = clean_problem_text(problem_text, remove_mc_choices=as_subjective)
    
    # í•´ì‹œ + generation_idë¡œ ë¬¸ì¥ ì„ íƒ
    hash_code = hash(cleaned_problem) + generation_id
    sent = request_sentences[hash_code % len(request_sentences)]['sent']
    
    # ë°°ì¹˜ ë°©ì‹ ê²°ì • (4ê°€ì§€ ë³€í˜•)
    variant = hash_code % 4
    if variant == 0:
        prompt = "\n".join([cleaned_problem, sent])
    elif variant == 1:
        prompt = "\n\n".join([cleaned_problem, sent])
    elif variant == 2:
        prompt = "\n".join([sent, cleaned_problem])
    else:
        prompt = "\n\n".join([sent, cleaned_problem])
    
    return prompt


# ============================================================================
# vLLM API í˜¸ì¶œ
# ============================================================================

def send_msg(prompt: str, base_url: str, model: str = "gpt-oss-120b"):
    """vLLM ì„œë²„ì— ìš”ì²­ì„ ë³´ë‚´ê³  ì‘ë‹µì„ ë°›ìŠµë‹ˆë‹¤."""
    client = OpenAI(base_url=base_url, api_key="dummy")
    messages = [{"role": "user", "content": prompt}]
    completion = client.chat.completions.create(
        model=model,
        messages=messages,
        reasoning_effort='high',
        temperature=1.0,
        top_p=1.0,
        timeout=60 * 60 * 24  # 24ì‹œê°„ íƒ€ì„ì•„ì›ƒ
    )
    return completion


# ============================================================================
# ì¶œë ¥ í˜•ì‹ ë³€í™˜
# ============================================================================

def format_output(problem: str, solution: str, answer: int, source: str, 
                  generation_id: int, format_type: str = "simple",
                  prompt: str = None) -> dict:
    """
    ê²°ê³¼ë¥¼ ì§€ì •ëœ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    ì§€ì› í˜•ì‹:
    - simple: ê°„ë‹¨í•œ problem/solution í˜•ì‹
    - sharegpt: ShareGPT ëŒ€í™” í˜•ì‹
    - alpaca: Alpaca instruction í˜•ì‹
    
    Args:
        prompt: get_prompt()ë¡œ ìƒì„±ëœ ì‹¤ì œ í”„ë¡¬í”„íŠ¸ (sharegpt/alpacaì—ì„œ ì‚¬ìš©)
    """
    cleaned_problem = clean_problem_text(problem)
    
    if format_type == "simple":
        return {
            "problem": cleaned_problem,
            "solution": solution,
            "answer": answer,
            "source": source,
            "generation_id": generation_id
        }
    
    elif format_type == "sharegpt":
        # promptê°€ ì œê³µë˜ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©, ì•„ë‹ˆë©´ cleaned_problem ì‚¬ìš©
        human_message = prompt if prompt else cleaned_problem
        return {
            "messages": [
                {"role": "user", "content": human_message},
                {"role": "assistant", "content": solution}
            ],
            "answer": answer
        }
    
    elif format_type == "alpaca":
        # promptê°€ ì œê³µë˜ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        if prompt:
            return {
                "instruction": prompt,
                "input": "",
                "output": solution,
                "answer": answer,
                "source": source,
                "generation_id": generation_id
            }
        else:
            return {
                "instruction": "ë‹¤ìŒ ìˆ˜í•™ ë¬¸ì œë¥¼ í’€ê³ , ìµœì¢… ë‹µì„ \\boxed{} ì•ˆì— ë„£ì–´ì£¼ì„¸ìš”.",
                "input": cleaned_problem,
                "output": solution,
                "answer": answer,
                "source": source,
                "generation_id": generation_id
            }
    
    else:
        raise ValueError(f"Unknown format type: {format_type}")


# ============================================================================
# í•­ëª© ì²˜ë¦¬
# ============================================================================

def process_item(idx: tuple, problems: list, request_sentences: list, 
                 output_dir: str, base_url: str, model: str, 
                 source: str, format_type: str, question_type: str = "multiples"):
    """
    ë‹¨ì¼ ë¬¸ì œ-ìƒì„± ìŒì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    
    Args:
        idx: (ë¬¸ì œ ì¸ë±ìŠ¤, ìƒì„± ì¸ë±ìŠ¤)
        question_type: "multiples" (ê°ê´€ì‹) ë˜ëŠ” "subjectives" (ì£¼ê´€ì‹)
    """
    problem_idx, gen_idx = idx
    output_path = f"{output_dir}/{problem_idx}_{gen_idx}.jsonl"
    
    # ì´ë¯¸ ì²˜ë¦¬ëœ ê²½ìš° ìŠ¤í‚µ
    if os.path.exists(output_path):
        return None
    
    req_start = time.time()
    start_stamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"SEND [{problem_idx}_{gen_idx}] ({question_type}) | st={start_stamp}")
    
    MAX_RETRIES = 10
    BACKOFF_FACTOR = 2
    
    item = problems[problem_idx]
    # ì£¼ê´€ì‹ì´ë©´ ì„ íƒì§€ ì œê±°
    as_subjective = (question_type == "subjectives")
    prompt = get_prompt(item['problem'], request_sentences, gen_idx, as_subjective=as_subjective)
    
    resp = None
    trial = 0
    for trial in range(MAX_RETRIES):
        try:
            resp = send_msg(prompt, base_url, model)
            if not resp:
                raise ValueError("ERROR WITHOUT RESPONSE")
            break
        except aiohttp.ClientError as e:
            time_stamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            print(f"[{problem_idx}_{gen_idx}] RETRY {trial + 1}/{MAX_RETRIES} | ERROR: {e}")
            if trial < MAX_RETRIES - 1:
                time.sleep(BACKOFF_FACTOR ** trial)
        except asyncio.TimeoutError as e:
            time_stamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            print(f"[{problem_idx}_{gen_idx}] TIMEOUT RETRY {trial + 1}/{MAX_RETRIES} | ERROR: {e}")
            if trial < MAX_RETRIES - 1:
                time.sleep(BACKOFF_FACTOR ** trial)
        except Exception as e:
            time_stamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            print(f"[{problem_idx}_{gen_idx}] EXCEPTION: {e}")
            return None
    
    if resp is None:
        print(f"[{problem_idx}_{gen_idx}] FAILED after {MAX_RETRIES} retries")
        return None
    
    # ì‘ë‹µ ì¶”ì¶œ (reasoning_contentê°€ ìˆìœ¼ë©´ <think> íƒœê·¸ë¡œ ê°ì‹¸ì„œ í¬í•¨)
    resp_dict = resp.choices[0].to_dict()
    message = resp_dict.get("message", {})
    
    if message.get("reasoning_content"):
        solution = f"<think>\n{message['reasoning_content'].strip()}\n</think>\n{message['content'].strip()}"
    else:
        solution = message.get("content", "")
    
    answer = item.get('answer', None)
    
    # ì£¼ê´€ì‹ ë²„ì „ì´ë©´ì„œ ì›ë³¸ì´ ê°ê´€ì‹ì¸ ê²½ìš°, ì‹¤ì œ ë‹µ ê°’ì„ ì¶”ì¶œ
    # (ì˜ˆ: answer=2, 2ë²ˆ ì„ íƒì§€ê°€ "\frac{1}{2}"ì´ë©´ â†’ real_answer="\frac{1}{2}")
    if as_subjective and is_multiple_choice(item['problem']) and answer is not None:
        real_answer = extract_choice_value(item['problem'], answer)
    else:
        real_answer = answer
    
    # í˜•ì‹ì— ë§ê²Œ ë³€í™˜ (ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ë„ ì „ë‹¬)
    formatted = format_output(
        problem=item['problem'],
        solution=solution,
        answer=real_answer,  # ì£¼ê´€ì‹ì€ ì‹¤ì œ ë‹µ ê°’, ê°ê´€ì‹ì€ ì„ íƒì§€ ë²ˆí˜¸
        source=source,
        generation_id=gen_idx,
        format_type=format_type,
        prompt=prompt  # boxed ë¬¸ì¥ì´ í¬í•¨ëœ ì‹¤ì œ í”„ë¡¬í”„íŠ¸
    )
    
    # ì €ì¥
    to_jsonl(output_path, [formatted])
    
    end_stamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    req_duration = time.time() - req_start
    
    print(f"DONE [{problem_idx}_{gen_idx}] | time={req_duration:.2f}s | trials={trial + 1}")
    return formatted


def run_generation(problems: list, request_sentences: list, output_dir: str,
                   base_url: str, model: str, source: str, format_type: str,
                   n: int = 10, max_workers: int = 200, question_type: str = "multiples",
                   retry_problems: list = None):
    """
    ëª¨ë“  ë¬¸ì œì— ëŒ€í•´ në²ˆì”© í’€ì´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        question_type: "multiples" (ê°ê´€ì‹) ë˜ëŠ” "subjectives" (ì£¼ê´€ì‹)
        retry_problems: ì¬ìƒì„±í•  ë¬¸ì œ ì¸ë±ìŠ¤ ëª©ë¡ (Noneì´ë©´ ëª¨ë“  ë¬¸ì œ ì²˜ë¦¬)
    """
    inputs = []
    
    if retry_problems is not None:
        # ì¬ìƒì„± ëª¨ë“œ: ì§€ì •ëœ ë¬¸ì œë§Œ ì²˜ë¦¬
        for problem_idx in retry_problems:
            for j in range(n):
                inputs.append((problem_idx, j))
        print(f"Retry mode: {len(inputs)} tasks ({len(retry_problems)} problems x {n} generations) [{question_type}]")
    else:
        # ì¼ë°˜ ëª¨ë“œ: ëª¨ë“  ë¬¸ì œ ì²˜ë¦¬
        for i in range(len(problems)):
            for j in range(n):
                inputs.append((i, j))
        print(f"Total tasks: {len(inputs)} ({len(problems)} problems x {n} generations) [{question_type}]")
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = [
            executor.submit(
                process_item, idx, problems, request_sentences, 
                output_dir, base_url, model, source, format_type, question_type
            ) 
            for idx in inputs
        ]
        for future in futures:
            future.result()


# ============================================================================
# ê²°ê³¼ ë³‘í•©
# ============================================================================

def merge_results(input_dirs: list, output_path: str):
    """
    ì—¬ëŸ¬ ë””ë ‰í† ë¦¬ì˜ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ JSONL íŒŒì¼ë¡œ ë³‘í•©í•©ë‹ˆë‹¤.
    """
    all_data = []
    
    for input_dir in input_dirs:
        if not os.path.exists(input_dir):
            print(f"Warning: Directory not found: {input_dir}")
            continue
        
        for entry in os.scandir(input_dir):
            if entry.name.endswith('.jsonl'):
                try:
                    data = open_jsonl(entry.path)
                    all_data.extend(data)
                except Exception as e:
                    print(f"Error reading {entry.path}: {e}")
    
    print(f"Total merged: {len(all_data)} items")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    to_jsonl(output_path, all_data)
    print(f"Saved to: {output_path}")
    
    return all_data


def find_data_files(data_dir: str) -> list:
    """data ë””ë ‰í† ë¦¬ì—ì„œ JSONL íŒŒì¼ë“¤ì„ ì°¾ìŠµë‹ˆë‹¤. (math, korean)"""
    patterns = ["*_math.jsonl", "*_korean.jsonl"]
    files = []
    for pattern in patterns:
        files.extend(glob.glob(os.path.join(data_dir, pattern)))
    return sorted(set(files))


def get_instruction_file_for_data_file(data_file: str) -> str:
    """
    ë°ì´í„° íŒŒì¼ëª…ì— ë”°ë¼ ì ì ˆí•œ instruction íŒŒì¼ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        data_file: ë°ì´í„° íŒŒì¼ ê²½ë¡œ ë˜ëŠ” íŒŒì¼ëª…
        
    Returns:
        instruction íŒŒì¼ëª…
    """
    filename = os.path.basename(data_file)
    if "_korean" in filename:
        return "sentences_ask_boxed_kr.jsonl"
    elif "_english" in filename:
        return "sentences_ask_boxed.jsonl"
    else:  # math ë˜ëŠ” ê¸°íƒ€
        return "sentences_ask_boxed_kr.jsonl"


def should_generate_subjective(data_file: str) -> bool:
    """
    ë°ì´í„° íŒŒì¼ëª…ì— ë”°ë¼ ì£¼ê´€ì‹ ìƒì„± ì—¬ë¶€ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
    
    Args:
        data_file: ë°ì´í„° íŒŒì¼ ê²½ë¡œ ë˜ëŠ” íŒŒì¼ëª…
        
    Returns:
        Trueë©´ ì£¼ê´€ì‹ë„ ìƒì„±, Falseë©´ ê°ê´€ì‹ë§Œ ìƒì„±
    """
    filename = os.path.basename(data_file)
    # mathì™€ koreanì€ ê°ê´€ì‹ë§Œ ìƒì„±
    if "_math" in filename or "_korean" in filename:
        return False
    # ê¸°íƒ€ (english ë“±)ëŠ” ì£¼ê´€ì‹ë„ ìƒì„± ê°€ëŠ¥
    return True


# ============================================================================
# ë©”ì¸
# ============================================================================

def main():
    import argparse
    
    parser = argparse.ArgumentParser(
        description="SFT í•™ìŠµ ë°ì´í„° ìƒì„±ê¸°",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  python generate_sft_data.py
  python generate_sft_data.py --n 20 --worker 40
  python generate_sft_data.py --input_file ./data/2025_math.jsonl
  python generate_sft_data.py --retry_file ./sft_output/.retry_queue.jsonl
        """
    )
    
    # ê²½ë¡œ ì„¤ì •
    parser.add_argument("--data_dir", default=DEFAULT_DATA_DIR, type=str,
                        help=f"ì…ë ¥ ë°ì´í„° ë””ë ‰í† ë¦¬ (ê¸°ë³¸: {DEFAULT_DATA_DIR})")
    parser.add_argument("--output_dir", default=DEFAULT_OUTPUT_DIR, type=str,
                        help=f"ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: {DEFAULT_OUTPUT_DIR})")
    parser.add_argument("--input_file", type=str, default=None,
                        help="íŠ¹ì • íŒŒì¼ë§Œ ì²˜ë¦¬ (ë¯¸ì§€ì •ì‹œ data_dir ë‚´ ëª¨ë“  *_math.jsonl, *_korean.jsonl, *_english.jsonl ì²˜ë¦¬)")
    
    # ìƒì„± ì„¤ì •
    parser.add_argument("--n", default=DEFAULT_N, type=int,
                        help=f"ë¬¸ì œë‹¹ ìƒì„± íšŸìˆ˜ (ê¸°ë³¸: {DEFAULT_N})")
    parser.add_argument("--worker", default=DEFAULT_WORKER, type=int,
                        help=f"ë™ì‹œ ì›Œì»¤ ìˆ˜ (ê¸°ë³¸: {DEFAULT_WORKER})")
    parser.add_argument("--format", default=DEFAULT_FORMAT, type=str,
                        choices=["simple", "sharegpt", "alpaca"],
                        help=f"ì¶œë ¥ í˜•ì‹ (ê¸°ë³¸: {DEFAULT_FORMAT})")
    
    # vLLM ì„œë²„ ì„¤ì •
    parser.add_argument("--base_url", default=DEFAULT_BASE_URL, type=str,
                        help=f"vLLM ì„œë²„ URL (ê¸°ë³¸: {DEFAULT_BASE_URL})")
    parser.add_argument("--model", default=DEFAULT_MODEL, type=str,
                        help=f"ëª¨ë¸ ì´ë¦„ (ê¸°ë³¸: {DEFAULT_MODEL})")
    
    # ì‹¤í–‰ ëª¨ë“œ
    parser.add_argument("--merge_only", action="store_true",
                        help="ìƒì„± ì—†ì´ ê¸°ì¡´ ê²°ê³¼ë§Œ ë³‘í•©")
    parser.add_argument("--retry_file", type=str, default=None,
                        help="ì¬ìƒì„±í•  ë¬¸ì œ ëª©ë¡ íŒŒì¼ ê²½ë¡œ (.retry_queue.jsonl)")
    parser.add_argument("--instruction_file", type=str, default=None,
                        help="í”„ë¡¬í”„íŠ¸ instruction íŒŒì¼ (ë¯¸ì§€ì •ì‹œ íŒŒì¼ëª…ì— ë”°ë¼ ìë™ ì„ íƒ: koreanâ†’sentences_ask_boxed_kr.jsonl, englishâ†’sentences_ask_boxed.jsonl, ê¸°íƒ€â†’sentences_ask_boxed_kr.jsonl)")
    
    args = parser.parse_args()
    
    # ì²˜ë¦¬í•  ë°ì´í„° íŒŒì¼ ëª©ë¡
    if args.input_file:
        data_files = [args.input_file]
    else:
        data_files = find_data_files(args.data_dir)
    
    if not data_files:
        raise FileNotFoundError(f"No data JSONL files found in {args.data_dir}")
    
    print(f"Found {len(data_files)} data files: {[os.path.basename(f) for f in data_files]}")
    
    # ê° íŒŒì¼ì— ëŒ€í•œ instruction íŒŒì¼ ë§¤í•‘
    file_instruction_map = {}
    for file_path in data_files:
        if args.instruction_file:
            # ëª…ì‹œì ìœ¼ë¡œ ì§€ì •ëœ ê²½ìš° ëª¨ë“  íŒŒì¼ì— ë™ì¼í•˜ê²Œ ì ìš©
            file_instruction_map[file_path] = args.instruction_file
        else:
            # íŒŒì¼ëª…ì— ë”°ë¼ ìë™ ì„ íƒ
            file_instruction_map[file_path] = get_instruction_file_for_data_file(file_path)
    
    # instruction íŒŒì¼ ë¡œë“œ (ê° íŒŒì¼ë³„ë¡œ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
    instruction_cache = {}  # {instruction_file: sentences_list}
    for file_path, instruction_file in file_instruction_map.items():
        if instruction_file not in instruction_cache:
            sentences_path = os.path.join(args.data_dir, instruction_file)
            if not os.path.exists(sentences_path):
                raise FileNotFoundError(f"{instruction_file} not found: {sentences_path}")
            instruction_cache[instruction_file] = open_jsonl(sentences_path)
            print(f"Loaded instruction file: {instruction_file}")
    
    # ì¬ìƒì„± íŒŒì¼ ë¡œë“œ
    retry_queue = {}  # {(source, question_type): [problem_indices]}
    if args.retry_file and os.path.exists(args.retry_file):
        retry_items = open_jsonl(args.retry_file)
        for item in retry_items:
            key = (item["source"], item["question_type"])
            if key not in retry_queue:
                retry_queue[key] = []
            retry_queue[key].append(item["problem_idx"])
        print(f"\nì¬ìƒì„± ëª¨ë“œ: {len(retry_items)}ê°œ ë¬¸ì œ ì¬ìƒì„± ì˜ˆì •")
        for (src, qtype), indices in retry_queue.items():
            print(f"  - {src}/{qtype}: ë¬¸ì œ {indices}")
    
    result_dirs = []
    
    if not args.merge_only:
        # ê° íŒŒì¼ ì²˜ë¦¬
        for file_path in data_files:
            file_name = os.path.basename(file_path)
            source = file_name.replace('.jsonl', '')
            
            print(f"\n{'='*60}")
            print(f"Processing: {file_name}")
            print(f"{'='*60}")
            
            problems = open_jsonl(file_path)
            print(f"Loaded {len(problems)} problems from {file_name}")
            
            # ì´ íŒŒì¼ì— ë§ëŠ” instruction íŒŒì¼ ì‚¬ìš©
            instruction_file = file_instruction_map[file_path]
            request_sentences = instruction_cache[instruction_file]
            print(f"Using instruction file: {instruction_file}")
            
            # í†µê³„ ì¶œë ¥
            mc_count = sum(1 for p in problems if is_multiple_choice(p['problem']))
            print(f"  - ê°ê´€ì‹ ë¬¸ì œ: {mc_count}ê°œ, ì£¼ê´€ì‹ ë¬¸ì œ: {len(problems) - mc_count}ê°œ")
            
            # íŒŒì¼ íƒ€ì…ì— ë”°ë¼ ì£¼ê´€ì‹ ìƒì„± ì—¬ë¶€ ê²°ì •
            generate_subjective = should_generate_subjective(file_path)
            
            # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì¤€ë¹„
            mc_output_dir = os.path.join(args.output_dir, source, "multiples")
            os.makedirs(mc_output_dir, exist_ok=True)
            result_dirs.append(mc_output_dir)
            
            # ì£¼ê´€ì‹ ë””ë ‰í† ë¦¬ëŠ” í•„ìš”í•  ë•Œë§Œ ìƒì„±
            if generate_subjective:
                subj_output_dir = os.path.join(args.output_dir, source, "subjectives")
                os.makedirs(subj_output_dir, exist_ok=True)
                result_dirs.append(subj_output_dir)
            else:
                subj_output_dir = None
                print(f"  - ì£¼ì˜: {source}ëŠ” ê°ê´€ì‹ë§Œ ìƒì„±ë©ë‹ˆë‹¤ (ì£¼ê´€ì‹ ìƒì„± ë¹„í™œì„±í™”)")
            
            # ì¬ìƒì„±í•  ë¬¸ì œ ëª©ë¡ í™•ì¸
            subj_retry = retry_queue.get((source, "subjectives"), None) if generate_subjective else None
            mc_retry = retry_queue.get((source, "multiples"), None)
            
            # ì¬ìƒì„± ëª¨ë“œì¼ ê²½ìš° ê¸°ì¡´ íŒŒì¼ ì‚­ì œ
            if subj_retry and subj_output_dir:
                print(f"\n[ì£¼ê´€ì‹ ì¬ìƒì„±] ë¬¸ì œ {subj_retry} ê¸°ì¡´ íŒŒì¼ ì‚­ì œ ì¤‘...")
                for problem_idx in subj_retry:
                    for gen_idx in range(args.n):
                        old_file = os.path.join(subj_output_dir, f"{problem_idx}_{gen_idx}.jsonl")
                        if os.path.exists(old_file):
                            os.remove(old_file)
                            print(f"  ì‚­ì œ: {old_file}")
            
            if mc_retry:
                print(f"\n[ê°ê´€ì‹ ì¬ìƒì„±] ë¬¸ì œ {mc_retry} ê¸°ì¡´ íŒŒì¼ ì‚­ì œ ì¤‘...")
                for problem_idx in mc_retry:
                    for gen_idx in range(args.n):
                        old_file = os.path.join(mc_output_dir, f"{problem_idx}_{gen_idx}.jsonl")
                        if os.path.exists(old_file):
                            os.remove(old_file)
                            print(f"  ì‚­ì œ: {old_file}")
            
            # ìƒì„±í•  íƒ€ì… ê²°ì •
            run_subj = (subj_retry or not retry_queue) and generate_subjective
            run_mc = mc_retry or not retry_queue
            
            # ì›Œì»¤ ë¶„ë°°: ë‘˜ ë‹¤ ì‹¤í–‰í•˜ë©´ ë°˜ë°˜, í•˜ë‚˜ë§Œì´ë©´ ì „ì²´ ì‚¬ìš©
            if run_subj and run_mc:
                # ğŸ”€ ì£¼ê´€ì‹/ê°ê´€ì‹ ë™ì‹œ ìƒì„± (ì›Œì»¤ ë°˜ë°˜ ë¶„ë°°)
                subj_workers = args.worker // 2
                mc_workers = args.worker - subj_workers  # í™€ìˆ˜ì¼ ê²½ìš° ê°ê´€ì‹ì— +1
                
                print(f"\n[ë™ì‹œ ìƒì„± ëª¨ë“œ] ì£¼ê´€ì‹ ì›Œì»¤: {subj_workers}, ê°ê´€ì‹ ì›Œì»¤: {mc_workers}")
                print(f"  - ì£¼ê´€ì‹: {len(subj_retry) if subj_retry else len(problems)}ê°œ ë¬¸ì œ")
                print(f"  - ê°ê´€ì‹: {len(mc_retry) if mc_retry else len(problems)}ê°œ ë¬¸ì œ")
                
                # ë‘ ìƒì„± ì‘ì—…ì„ ë™ì‹œì— ì‹¤í–‰
                with ThreadPoolExecutor(max_workers=2) as type_executor:
                    if subj_output_dir:
                        subj_future = type_executor.submit(
                            run_generation,
                            problems=problems,
                            request_sentences=request_sentences,
                            output_dir=subj_output_dir,
                            base_url=args.base_url,
                            model=args.model,
                            source=source,
                            format_type=args.format,
                            n=args.n,
                            max_workers=subj_workers,
                            question_type="subjectives",
                            retry_problems=subj_retry
                        )
                    else:
                        subj_future = None
                    mc_future = type_executor.submit(
                        run_generation,
                        problems=problems,
                        request_sentences=request_sentences,
                        output_dir=mc_output_dir,
                        base_url=args.base_url,
                        model=args.model,
                        source=source,
                        format_type=args.format,
                        n=args.n,
                        max_workers=mc_workers,
                        question_type="multiples",
                        retry_problems=mc_retry
                    )
                    
                    # ì™„ë£Œ ëŒ€ê¸°
                    if subj_future:
                        subj_future.result()
                    mc_future.result()
                    
            elif run_subj:
                # ì£¼ê´€ì‹ë§Œ ìƒì„± (ì „ì²´ ì›Œì»¤ ì‚¬ìš©)
                print(f"\n[ì£¼ê´€ì‹ ë²„ì „ ìƒì„± ì‹œì‘] ({len(subj_retry) if subj_retry else len(problems)}ê°œ ë¬¸ì œ)")
                run_generation(
                    problems=problems,
                    request_sentences=request_sentences,
                    output_dir=subj_output_dir,
                    base_url=args.base_url,
                    model=args.model,
                    source=source,
                    format_type=args.format,
                    n=args.n,
                    max_workers=args.worker,
                    question_type="subjectives",
                    retry_problems=subj_retry
                )
                
            elif run_mc:
                # ê°ê´€ì‹ë§Œ ìƒì„± (ì „ì²´ ì›Œì»¤ ì‚¬ìš©)
                print(f"\n[ê°ê´€ì‹ ë²„ì „ ìƒì„± ì‹œì‘] ({len(mc_retry) if mc_retry else len(problems)}ê°œ ë¬¸ì œ)")
                run_generation(
                    problems=problems,
                    request_sentences=request_sentences,
                    output_dir=mc_output_dir,
                    base_url=args.base_url,
                    model=args.model,
                    source=source,
                    format_type=args.format,
                    n=args.n,
                    max_workers=args.worker,
                    question_type="multiples",
                    retry_problems=mc_retry
                )
    else:
        # merge_only ëª¨ë“œ: ê¸°ì¡´ ë””ë ‰í† ë¦¬ ì°¾ê¸°
        for file_path in data_files:
            source = os.path.basename(file_path).replace('.jsonl', '')
            # multiplesëŠ” í•­ìƒ, subjectivesëŠ” íŒŒì¼ íƒ€ì…ì— ë”°ë¼
            qtypes = ["multiples"]
            if should_generate_subjective(file_path):
                qtypes.append("subjectives")
            
            for qtype in qtypes:
                each_output_dir = os.path.join(args.output_dir, source, qtype)
                if os.path.exists(each_output_dir):
                    result_dirs.append(each_output_dir)
    
    # ê²°ê³¼ ë³‘í•©
    print(f"\n{'='*60}")
    print("Merging results...")
    print(f"{'='*60}")
    
    merged_dir = os.path.join(args.output_dir, "merged")
    merged_path = os.path.join(merged_dir, f"sft_math_all_{args.format}.jsonl")
    
    merge_results(result_dirs, merged_path)
    
    print("\nDONE!")


if __name__ == "__main__":
    main()